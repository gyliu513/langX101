{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import functools\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from genai.credentials import Credentials\n",
    "from genai.model import Model\n",
    "from genai.schemas import GenerateParams\n",
    "\n",
    "from langfuse import Langfuse\n",
    "from langfuse.client import InitialGeneration\n",
    "from langfuse.api.resources.commons.types.llm_usage import LlmUsage\n",
    "\n",
    "from langfuse.model import Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateArgsExtractor:\n",
    "    def __init__(self, name=None, metadata=None, trace_id=None, **kwargs):\n",
    "        self.args = {}\n",
    "        # self.args[\"name\"] = name\n",
    "        # self.args[\"metadata\"] = metadata\n",
    "        # self.args[\"trace_id\"] = trace_id\n",
    "        self.kwargs = {\"prompts\": metadata}\n",
    "\n",
    "    def get_langfuse_args(self):\n",
    "        return {**self.args, **self.kwargs}\n",
    "\n",
    "    def get_watsonx_args(self):\n",
    "        return self.kwargs\n",
    "\n",
    "\n",
    "class WatsonxLangfuse:\n",
    "    _instance = None\n",
    "    _lock = threading.Lock()\n",
    "\n",
    "    def __new__(cls):\n",
    "        if not cls._instance:\n",
    "            with cls._lock:\n",
    "                if not cls._instance:\n",
    "                    cls._instance = super(WatsonxLangfuse, cls).__new__(cls)\n",
    "                    cls._instance.initialize()\n",
    "        return cls._instance\n",
    "\n",
    "    def initialize(self):\n",
    "        self.langfuse = Langfuse()\n",
    "\n",
    "    @classmethod\n",
    "    def flush(cls):\n",
    "        cls._instance.langfuse.flush()\n",
    "\n",
    "    def _get_call_details(self, result, api_resource_class, **kwargs):\n",
    "        # name = kwargs.get(\"name\", \"Watsonx-generation\")\n",
    "        now = datetime.now()\n",
    "        timestamp_str = now.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "        # name = \"Watsonx-generation-xxxxxxx\" + timestamp_str\n",
    "        name = \"Watsonx-generation-\" + timestamp_str\n",
    "\n",
    "        if name is not None and not isinstance(name, str):\n",
    "            raise TypeError(\"name must be a string\")\n",
    "\n",
    "        trace_id = kwargs.get(\"trace_id\", \"ed63f363-f8fa-4985-aecf-01d8e6507645\")\n",
    "        if trace_id is not None and not isinstance(trace_id, str):\n",
    "            raise TypeError(\"trace_id must be a string\")\n",
    "\n",
    "        # metadata = kwargs.get(\"metadata\", {})\n",
    "        # metadata = {}\n",
    "\n",
    "        metadata = {\n",
    "            \"interface\": \"whatsapp\"\n",
    "        }\n",
    "        if metadata is not None and not isinstance(metadata, dict):\n",
    "            raise TypeError(\"metadata must be a dictionary\")\n",
    "\n",
    "        completion = None\n",
    "\n",
    "        if api_resource_class == Model:\n",
    "            print(\"generate\")\n",
    "            completion = \"oooooook\"\n",
    "        else:\n",
    "            completion = None\n",
    "\n",
    "        model = \"google/flan-ul2\"\n",
    "        # model = \"gpt-3.5-turbo\"\n",
    "        # model = kwargs.get(\"model\", None) if isinstance(result, Exception) else result.model\n",
    "\n",
    "        # usage = None if isinstance(result, Exception) or result.usage is None else LlmUsage(**result.usage)\n",
    "        endTime = datetime.now()\n",
    "        '''\n",
    "        usage = {\n",
    "            \"promptTokens\": 50,\n",
    "            \"completionTokens\": 49\n",
    "        }\n",
    "        '''\n",
    "        usage = None\n",
    "        '''\n",
    "        all_details = {\n",
    "            # \"status_message\": str(result) if isinstance(result, Exception) else None,\n",
    "            \"name\": name,\n",
    "            \"prompt\": [\"What is 1 + 1?\"],\n",
    "            \"completion\": completion,\n",
    "            \"endTime\": endTime,\n",
    "            \"model\": model,\n",
    "            \"modelParameters\": {\"maxTokens\": \"1000\", \"temperature\": \"0.9\"},\n",
    "            \"usage\": usage,\n",
    "            \"metadata\": metadata,\n",
    "            # \"level\": \"ERROR\" if isinstance(result, Exception) else \"DEFAULT\",\n",
    "            \"trace_id\": trace_id,\n",
    "        }\n",
    "        '''\n",
    "        generationStartTime = datetime.now()\n",
    "        all_details = {\n",
    "            \"name\": name,\n",
    "            # \"startTime\": generationStartTime,\n",
    "            \"endTime\": endTime,\n",
    "            # \"endTime\": datetime.now(),\n",
    "            \"model\": model,\n",
    "            \"modelParameters\": {\"maxTokens\": \"1000\", \"temperature\": \"0.9\"},\n",
    "            \"prompt\": [\"What is 1 + 1?\"],\n",
    "            \"completion\": completion,\n",
    "            \"usage\": usage,\n",
    "            \"metadata\": metadata,\n",
    "            # \"trace_id\": trace_id,\n",
    "            # \"prompt\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Please generate a summary of the following documents \\nThe engineering department defined the following OKR goals...\\nThe marketing department defined the following OKR goals...\"}],\n",
    "            # \"completion\": \"The Q3 OKRs contain goals for multiple teams...\",\n",
    "            # \"usage\": Usage(promptTokens=50, completionTokens = 49),\n",
    "            # \"metadata\": {\"interface\": \"whatsapp\"}\n",
    "        }\n",
    "        return all_details\n",
    "\n",
    "    def _log_result(self, call_details):\n",
    "        '''\n",
    "        generationStartTime = datetime.now()\n",
    "\n",
    "        generation2 = self.langfuse.generation(InitialGeneration(\n",
    "          name=\"summary-generation-watsonx\",\n",
    "          startTime=generationStartTime,\n",
    "          endTime=datetime.now(),\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          modelParameters={\"maxTokens\": \"1000\", \"temperature\": \"0.9\"},\n",
    "          prompt=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Please generate a summary of the following documents \\nThe engineering department defined the following OKR goals...\\nThe marketing department defined the following OKR goals...\"}],\n",
    "          completion=\"The Q3 OKRs contain goals for multiple teams...\",\n",
    "          usage=Usage(promptTokens=50, completionTokens = 49),\n",
    "          metadata={\"interface\": \"whatsapp\"}\n",
    "        ))\n",
    "        '''\n",
    "        print(call_details)\n",
    "        generation = InitialGeneration(**call_details)\n",
    "        self.langfuse.generation(generation)\n",
    "\n",
    "    def instrument_method(self, cls, method_name):\n",
    "        method = getattr(cls, method_name)\n",
    "\n",
    "        @functools.wraps(method)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            print(f\"Before calling {method.__name__}\")\n",
    "            arg_extractor = CreateArgsExtractor(*args, **kwargs)\n",
    "            startTime = datetime.now()\n",
    "            result = method(*args, **kwargs)\n",
    "            print(f\"After calling {method.__name__}\")\n",
    "            call_details = self._get_call_details(result, cls, **arg_extractor.get_langfuse_args())\n",
    "            call_details[\"startTime\"] = startTime\n",
    "            self._log_result(call_details)\n",
    "            return result\n",
    "\n",
    "        setattr(cls, method_name, wrapper)\n",
    "        setattr(Model, \"flush_langfuse\", self.flush)\n",
    "\n",
    "'''\n",
    "    def langfuse_modified(self, func, api_resource_class):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                arg_extractor = CreateArgsExtractor(*args, **kwargs)\n",
    "                result = func(api_resource_class, prompts=aliceq)\n",
    "                # result = func(**arg_extractor.get_watsonx_args())\n",
    "                call_details = self._get_call_details(result, api_resource_class, **arg_extractor.get_langfuse_args())\n",
    "                call_details[\"startTime\"] = startTime\n",
    "                self._log_result(call_details)\n",
    "            except Exception as ex:\n",
    "                # call_details = self._get_call_details(ex, api_resource_class, **arg_extractor.get_langfuse_args())\n",
    "                # call_details[\"startTime\"] = startTime\n",
    "                # self._log_result(call_details)\n",
    "                raise ex\n",
    "\n",
    "            return result\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    def replace_watsonx_funcs(self):\n",
    "        api_resources_classes = [\n",
    "            (Model, \"generate\"),\n",
    "        ]\n",
    "\n",
    "        for api_resource_class, method in api_resources_classes:\n",
    "            generate_method = getattr(api_resource_class, method)\n",
    "            setattr(api_resource_class, method, self.langfuse_modified(generate_method, api_resource_class))\n",
    "'''\n",
    "\n",
    "'''\n",
    "def instrument_method(cls, method_name):\n",
    "    method = getattr(cls, method_name)\n",
    "\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"Before calling {method.__name__}\")\n",
    "        result = method(*args, **kwargs)\n",
    "        print(f\"After calling {method.__name__}\")\n",
    "        return result\n",
    "\n",
    "    setattr(cls, method_name, wrapper)\n",
    "\n",
    "# Instrument the 'display' method of the SimpleClass\n",
    "instrument_method(SimpleClass, 'display')\n",
    "'''\n",
    "\n",
    "modifier = WatsonxLangfuse()\n",
    "modifier.instrument_method(Model, \"generate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice][Q] What is IBM Cloud Pak for Watson AIOps?\n",
      "Before calling generate\n",
      "Before calling generate\n",
      "After calling generate\n",
      "generate\n",
      "{'name': 'Watsonx-generation-2023-11-02-11:12:49', 'endTime': datetime.datetime(2023, 11, 2, 11, 12, 49, 266110), 'model': 'google/flan-ul2', 'modelParameters': {'maxTokens': '1000', 'temperature': '0.9'}, 'prompt': ['What is 1 + 1?'], 'completion': 'oooooook', 'usage': {'promptTokens': 50, 'completionTokens': 49}, 'metadata': {'interface': 'whatsapp'}, 'startTime': datetime.datetime(2023, 11, 2, 11, 12, 48, 519313)}\n",
      "After calling generate\n",
      "generate\n",
      "{'name': 'Watsonx-generation-2023-11-02-11:12:49', 'endTime': datetime.datetime(2023, 11, 2, 11, 12, 49, 266348), 'model': 'google/flan-ul2', 'modelParameters': {'maxTokens': '1000', 'temperature': '0.9'}, 'prompt': ['What is 1 + 1?'], 'completion': 'oooooook', 'usage': None, 'metadata': {'interface': 'whatsapp'}, 'startTime': datetime.datetime(2023, 11, 2, 11, 12, 48, 519302)}\n",
      "[Bob][A] IBM Cloud Pak for Watson AIOps is an open source software package available on the IBM Cloud, for the purpose\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "id='af84bd16-9ab3-4529-8ec2-300aa3d2ac23' trace_id='a109af6b-2883-4872-af74-b073b83d2938' trace_id_type=None name='Watsonx-generation-2023-11-02-11:12:49' start_time=datetime.datetime(2023, 11, 2, 11, 12, 48, 519302) metadata={'interface': 'whatsapp'} input=None output=None level=None status_message=None parent_observation_id=None version=None end_time=datetime.datetime(2023, 11, 2, 11, 12, 49, 266348) completion_start_time=None model='google/flan-ul2' model_parameters={'maxTokens': '1000', 'temperature': '0.9'} prompt=['What is 1 + 1?'] completion='oooooook' usage=None\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "id='cba3aded-39df-4cf8-b358-583fad1f6155' trace_id='60ca1928-9c63-4ecb-b8e5-cfa53ec125e4' trace_id_type=None name='Watsonx-generation-2023-11-02-11:12:49' start_time=datetime.datetime(2023, 11, 2, 11, 12, 48, 519313) metadata={'interface': 'whatsapp'} input=None output=None level=None status_message=None parent_observation_id=None version=None end_time=datetime.datetime(2023, 11, 2, 11, 12, 49, 266110) completion_start_time=None model='google/flan-ul2' model_parameters={'maxTokens': '1000', 'temperature': '0.9'} prompt=['What is 1 + 1?'] completion='oooooook' usage=LlmUsage(prompt_tokens=50, completion_tokens=49, total_tokens=None)\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "api_endpoint = os.getenv(\"GENAI_API\", None)\n",
    "\n",
    "bob_params = GenerateParams(\n",
    "    decoding_method=\"sample\",\n",
    "    max_new_tokens=25,\n",
    "    min_new_tokens=1,\n",
    "    stream=False,\n",
    "    temperature=1,\n",
    "    top_k=50,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "creds = Credentials(api_key, api_endpoint)\n",
    "bob_model = Model(\"google/flan-ul2\", params=bob_params, credentials=creds)\n",
    "\n",
    "alice_q = \"What is IBM Cloud Pak for Watson AIOps?\"\n",
    "print(f\"[Alice][Q] {alice_q}\")\n",
    "\n",
    "bob_response = bob_model.generate([alice_q])\n",
    "bob_a = bob_response[0].generated_text\n",
    "print(f\"[Bob][A] {bob_a}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ycliu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
