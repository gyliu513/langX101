{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc935871-7640-41c6-b798-58514d860fe0",
   "metadata": {},
   "source": [
    "## LLaMA2 chat with SQL\n",
    "\n",
    "Open source, local LLMs are great to consider for any application that demands data privacy.\n",
    "\n",
    "SQL is one good example. \n",
    "\n",
    "This cookbook shows how to perform text-to-SQL using various local versions of LLaMA2 run locally.\n",
    "\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81adcf8b-395a-4f02-8749-ac976942b446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/gyliu/py311/lib/python3.11/site-packages (0.0.339)\n",
      "Collecting replicate\n",
      "  Obtaining dependency information for replicate from https://files.pythonhosted.org/packages/dc/e1/9376a3d8842dd8685b16e72ac8217163367118e62fd9daa8b617eca3303f/replicate-0.20.0-py3-none-any.whl.metadata\n",
      "  Downloading replicate-0.20.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (0.6.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (0.0.64)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (2.5.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from replicate) (0.25.1)\n",
      "Requirement already satisfied: packaging in /Users/gyliu/py311/lib/python3.11/site-packages (from replicate) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from replicate) (4.8.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gyliu/py311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/gyliu/py311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gyliu/py311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/gyliu/py311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/gyliu/py311/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/gyliu/py311/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/gyliu/py311/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate) (2023.7.22)\n",
      "Requirement already satisfied: httpcore in /Users/gyliu/py311/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate) (1.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/gyliu/py311/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /Users/gyliu/py311/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.14.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gyliu/py311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/gyliu/py311/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/gyliu/py311/lib/python3.11/site-packages (from httpcore->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
      "Downloading replicate-0.20.0-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: replicate\n",
      "Successfully installed replicate-0.20.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13ed66-300b-4a23-b8ac-44df68ee4733",
   "metadata": {},
   "source": [
    "## LLM\n",
    "\n",
    "There are a few ways to access LLaMA2.\n",
    "\n",
    "To run locally, we use Ollama.ai. \n",
    "\n",
    "See [here](https://python.langchain.com/docs/integrations/chat/ollama) for details on installation and setup.\n",
    "\n",
    "Also, see [here](https://python.langchain.com/docs/guides/local_llms) for our full guide on local LLMs.\n",
    " \n",
    "To use an external API, which is not private, we can use Replicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a75a5c6-34ee-4ab9-a664-d9b432d812ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Init param `input` is deprecated, please use `model_kwargs` instead.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Replicate\n__root__\n  Did not find replicate_api_token, please add an environment variable `REPLICATE_API_TOKEN` which contains it, or pass  `replicate_api_token` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/gyliu/go/src/github.com/gyliu513/langX101/langchain/cookbook/LLaMA2_sql_chat.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyliu/go/src/github.com/gyliu513/langX101/langchain/cookbook/LLaMA2_sql_chat.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# REPLICATE_API_TOKEN = getpass()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyliu/go/src/github.com/gyliu513/langX101/langchain/cookbook/LLaMA2_sql_chat.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyliu/go/src/github.com/gyliu513/langX101/langchain/cookbook/LLaMA2_sql_chat.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m replicate_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmeta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gyliu/go/src/github.com/gyliu513/langX101/langchain/cookbook/LLaMA2_sql_chat.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m llama2_chat_replicate \u001b[39m=\u001b[39m Replicate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyliu/go/src/github.com/gyliu513/langX101/langchain/cookbook/LLaMA2_sql_chat.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     model\u001b[39m=\u001b[39;49mreplicate_id, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0.01\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m500\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1\u001b[39;49m}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyliu/go/src/github.com/gyliu513/langX101/langchain/cookbook/LLaMA2_sql_chat.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[0;32m~/py311/lib/python3.11/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/py311/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Replicate\n__root__\n  Did not find replicate_api_token, please add an environment variable `REPLICATE_API_TOKEN` which contains it, or pass  `replicate_api_token` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "# Local\n",
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "llama2_chat = ChatOllama(model=\"llama2:13b-chat\")\n",
    "llama2_code = ChatOllama(model=\"codellama:7b-instruct\")\n",
    "\n",
    "# API\n",
    "from langchain.llms import Replicate\n",
    "\n",
    "# REPLICATE_API_TOKEN = getpass()\n",
    "# os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n",
    "replicate_id = \"meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d\"\n",
    "llama2_chat_replicate = Replicate(\n",
    "    model=replicate_id, model_kwargs={\"temperature\": 0.01, \"max_length\": 500, \"top_p\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce96f7ea-b3d5-44e1-9fa5-a79e04a9e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply set the LLM we want to use\n",
    "llm = llama2_chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80222165-f353-4e35-a123-5f70fd70c6c8",
   "metadata": {},
   "source": [
    "## DB\n",
    "\n",
    "Connect to a SQLite DB.\n",
    "\n",
    "To create this particular DB, you can use the code and follow the steps shown [here](https://github.com/facebookresearch/llama-recipes/blob/main/demo_apps/StructuredLlama.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025bdd82-3bb1-4948-bc7c-c3ccd94fd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///nba_roster.db\", sample_rows_in_table_info=0)\n",
    "\n",
    "\n",
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b3577-baa2-4e12-a393-f40e5db49ac7",
   "metadata": {},
   "source": [
    "## Query a SQL DB \n",
    "\n",
    "Follow the runnables workflow [here](https://python.langchain.com/docs/expression_language/cookbook/sql_db)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4933ea-d9c0-4b0a-8177-ba4490c6532b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' SELECT \"Team\" FROM nba_roster WHERE \"NAME\" = \\'Klay Thompson\\';'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Given an input question, convert it to a SQL query. No pre-amble.\"),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain to query\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sql_response.invoke({\"question\": \"What team is Klay Thompson on?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9e2c8-9b88-4853-ac86-001bc6cc6695",
   "metadata": {},
   "source": [
    "We can review the results:\n",
    "\n",
    "* [LangSmith trace](https://smith.langchain.com/public/afa56a06-b4e2-469a-a60f-c1746e75e42b/r) LLaMA2-13 Replicate API\n",
    "* [LangSmith trace](https://smith.langchain.com/public/2d4ecc72-6b8f-4523-8f0b-ea95c6b54a1d/r) LLaMA2-13 local \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a2825e3-c1b6-4f7d-b9c9-d9835de323bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' Based on the table schema and SQL query, there are 30 unique teams in the NBA.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain to answer\n",
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question and SQL response, convert it to a natural langugae answer. No pre-amble.\",\n",
    "        ),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response)\n",
    "    | RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: db.run(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")\n",
    "\n",
    "full_chain.invoke({\"question\": \"How many unique teams are there?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17b3ee-6618-4681-b6df-089bbb5ffcd7",
   "metadata": {},
   "source": [
    "We can review the results:\n",
    "\n",
    "* [LangSmith trace](https://smith.langchain.com/public/10420721-746a-4806-8ecf-d6dc6399d739/r) LLaMA2-13 Replicate API\n",
    "* [LangSmith trace](https://smith.langchain.com/public/5265ebab-0a22-4f37-936b-3300f2dfa1c1/r) LLaMA2-13 local "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85381b-1edc-4bb3-a7bd-2ab23f81e54d",
   "metadata": {},
   "source": [
    "## Chat with a SQL DB \n",
    "\n",
    "Next, we can add memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022868f2-128e-42f5-8d90-d3bb2f11d994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' SELECT \"Team\" FROM nba_roster WHERE \"NAME\" = \\'Klay Thompson\\';'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "template = \"\"\"Given an input question, convert it to a SQL query. No pre-amble. Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# Chain to query with memory\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        history=RunnableLambda(lambda x: memory.load_memory_variables(x)[\"history\"]),\n",
    "    )\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "def save(input_output):\n",
    "    output = {\"output\": input_output.pop(\"output\")}\n",
    "    memory.save_context(input_output, output)\n",
    "    return output[\"output\"]\n",
    "\n",
    "\n",
    "sql_response_memory = RunnablePassthrough.assign(output=sql_chain) | save\n",
    "sql_response_memory.invoke({\"question\": \"What team is Klay Thompson on?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "800a7a3b-f411-478b-af51-2310cd6e0425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' Sure! Here\\'s the natural language response based on the given input:\\n\\n\"Klay Thompson\\'s salary is $43,219,440.\"')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain to answer\n",
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question and SQL response, convert it to a natural langugae answer. No pre-amble.\",\n",
    "        ),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response_memory)\n",
    "    | RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: db.run(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")\n",
    "\n",
    "full_chain.invoke({\"question\": \"What is his salary?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77fee61-f4da-4bb1-8285-14101e505518",
   "metadata": {},
   "source": [
    "Here is the [trace](https://smith.langchain.com/public/54794d18-2337-4ce2-8b9f-3d8a2df89e51/r)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
