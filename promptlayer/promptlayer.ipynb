{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: promptlayer in /Users/guangyaliu/ycliu/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/guangyaliu/ycliu/lib/python3.10/site-packages (from promptlayer) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/guangyaliu/ycliu/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->promptlayer) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/guangyaliu/ycliu/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->promptlayer) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/guangyaliu/ycliu/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->promptlayer) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/guangyaliu/ycliu/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->promptlayer) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install promptlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Maria.\n",
      "I am 22 years old and from the United Kingdom.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instead of `import openai` we will use\n",
    "openai = promptlayer.openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Make a completion to OpenAI\n",
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\", \n",
    "  prompt=\"My name is\",\n",
    ")\n",
    "print(response.choices[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ashley and I have 3 years of experience as a back-end developer. I\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\", \n",
    "  prompt=\"My name is\",\n",
    "  pl_tags=[\"getting_started_example\"] # üç∞ PromptLayer tags\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-8IJeXo0GJxpaglGmVXegnCNciM1oZ at 0x11c374f40> JSON: {\n",
       "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
       "  \"id\": \"cmpl-8IJeXo0GJxpaglGmVXegnCNciM1oZ\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1699376141,\n",
       "  \"model\": \"text-ada-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \" capitalized\\n\\nHaley\\n\\nHello Haley!\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 3,\n",
       "    \"completion_tokens\": 11,\n",
       "    \"total_tokens\": 14\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import promptlayer\n",
    "import os\n",
    "promptlayer.api_key = os.environ.get(\"PROMPTLAYER_API_KEY\")\n",
    "\n",
    "# Swap out your 'import openai'\n",
    "openai = promptlayer.openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Do something fun üöÄ\n",
    "openai.Completion.create(\n",
    "  engine=\"text-ada-001\", \n",
    "  prompt=\"My name is\", \n",
    "  pl_tags=[\"name-guessing\", \"pipeline-2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Albany.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, pl_request_id = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\", \n",
    "  prompt=\"What is the capital of New York? \\\\n\\\\nThe capital of New York is\",\n",
    "  pl_tags=[\"getting_started_example\"],\n",
    "  return_pl_id=True # Make sure to set this to True\n",
    ")\n",
    "\n",
    "answer = response.choices[0].text\n",
    "print(answer)\n",
    "correct_answer = \"albany\" in answer.lower()\n",
    "\n",
    "# Log score to üç∞ PromptLayer\n",
    "promptlayer.track.score(\n",
    "    request_id=pl_request_id,\n",
    "    score=100 if correct_answer else 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7\n",
      "Numeric answer: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"You are an AI assistant that helps travelers pick a city to travel to. \n",
    "You do this by rating how much a person would enjoy a city based on their interests.\n",
    "Given a city and interests, you respond with an integer 1-10 where 10 is the most enjoyment and 0 is the least.\n",
    "\n",
    "Sample city: New York City\n",
    "Sample interests: food, museums, hiking\n",
    "Sample answer: 8\n",
    "\n",
    "City: {city}\n",
    "Interests: {interests}\n",
    "Answer: \"\"\"\n",
    "\n",
    "response, pl_request_id = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\", \n",
    "  prompt=prompt_template.format(city=\"Washington, D.C.\", interests=\"resorts, museums, beaches\"),\n",
    "  pl_tags=[\"getting_started_example\"],\n",
    "  return_pl_id=True\n",
    ")\n",
    "\n",
    "answer = response.choices[0].text\n",
    "print(answer)\n",
    "\n",
    "# Let's convert the answer to an int\n",
    "numeric_answer = None\n",
    "error_message = None\n",
    "try:\n",
    "    numeric_answer = int(answer.strip())\n",
    "except ValueError as e:\n",
    "    error_message = str(e)\n",
    "    pass\n",
    "\n",
    "# Use score in üç∞ PromptLayer to track if answer was an int\n",
    "promptlayer.track.score(\n",
    "    request_id=pl_request_id,\n",
    "    score=100 if numeric_answer else 0,\n",
    ")\n",
    "\n",
    "print(\"Numeric answer:\", numeric_answer)\n",
    "\n",
    "# Log metadata for request in üç∞ PromptLayer\n",
    "promptlayer.track.metadata(\n",
    "    request_id=pl_request_id,\n",
    "    metadata={\n",
    "        \"referrer\": \"getting_started.ipynb\",\n",
    "        \"origin\": \"NYC, USA\",\n",
    "        \"user_id\": \"sdf328\",\n",
    "        \"error_message\": \"No error\" if numeric_answer else error_message,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "PromptLayer had the following error while getting your prompt: Prompt not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/guangyaliu/go/src/github.com/gyliu513/langX101/promptlayer/promptlayer.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guangyaliu/go/src/github.com/gyliu513/langX101/promptlayer/promptlayer.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m city_choice_prompt \u001b[39m=\u001b[39m promptlayer\u001b[39m.\u001b[39;49mprompts\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcity_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangyaliu/go/src/github.com/gyliu513/langX101/promptlayer/promptlayer.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m city_choice_prompt_v1 \u001b[39m=\u001b[39m promptlayer\u001b[39m.\u001b[39mprompts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcity_choice\u001b[39m\u001b[39m\"\u001b[39m, version\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangyaliu/go/src/github.com/gyliu513/langX101/promptlayer/promptlayer.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m city_choice_prompt_prod \u001b[39m=\u001b[39m promptlayer\u001b[39m.\u001b[39mprompts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcity_choice\u001b[39m\u001b[39m\"\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprod\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ycliu/lib/python3.10/site-packages/promptlayer/prompts/prompts.py:29\u001b[0m, in \u001b[0;36mget_prompt\u001b[0;34m(prompt_name, langchain, version, label, include_metadata)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mGet a prompt template from PromptLayer.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mprompt_name: the prompt name\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39minclude_metadata: Whether or not to include the metadata of the prompt in the response.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m api_key \u001b[39m=\u001b[39m get_api_key()\n\u001b[0;32m---> 29\u001b[0m prompt \u001b[39m=\u001b[39m promptlayer_get_prompt(prompt_name, api_key, version, label)\n\u001b[1;32m     30\u001b[0m \u001b[39mif\u001b[39;00m langchain:\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m prompt[\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/ycliu/lib/python3.10/site-packages/promptlayer/utils.py:203\u001b[0m, in \u001b[0;36mpromptlayer_get_prompt\u001b[0;34m(prompt_name, api_key, version, label)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPromptLayer had the following error while getting your prompt: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m request_response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m--> 203\u001b[0m     raise_on_bad_response(\n\u001b[1;32m    204\u001b[0m         request_response,\n\u001b[1;32m    205\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mPromptLayer had the following error while getting your prompt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    206\u001b[0m     )\n\u001b[1;32m    208\u001b[0m \u001b[39mreturn\u001b[39;00m request_response\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/ycliu/lib/python3.10/site-packages/promptlayer/utils.py:413\u001b[0m, in \u001b[0;36mraise_on_bad_response\u001b[0;34m(request_response, main_message)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(request_response, \u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    412\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmain_message\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mrequest_response\u001b[39m.\u001b[39mjson()\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    414\u001b[0m     \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError:\n\u001b[1;32m    415\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmain_message\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mrequest_response\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: PromptLayer had the following error while getting your prompt: Prompt not found"
     ]
    }
   ],
   "source": [
    "city_choice_prompt = promptlayer.prompts.get(\"city_choice\")\n",
    "city_choice_prompt_v1 = promptlayer.prompts.get(\"city_choice\", version=1)\n",
    "city_choice_prompt_prod = promptlayer.prompts.get(\"city_choice\", label=\"prod\")\n",
    "print(city_choice_prompt_v1['template'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nI am 5\\'7\" tall.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import promptlayer # Don't forget this üç∞\n",
    "from langchain.callbacks import PromptLayerCallbackHandler\n",
    "\n",
    "# OpenAI Completion Model\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name=\"text-davinci-003\",\n",
    "    callbacks=[\n",
    "        PromptLayerCallbackHandler(pl_tags=[\"langchain\"])\n",
    "    ],\n",
    ")\n",
    "llm(\"How tall are you?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ycliu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
